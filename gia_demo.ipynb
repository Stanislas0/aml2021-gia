{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc4e5087",
   "metadata": {},
   "source": [
    "# Demo of graph injection attack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba61f7d7",
   "metadata": {},
   "source": [
    "In this demo, we will show a completed process of applying the graph injection attack in a [refined CORA](https://github.com/THUDM/Refined-cora-citeseer) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "feb1976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc83eceb",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda0ffb3",
   "metadata": {},
   "source": [
    "### 1.1. Load CORA (refined) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49063d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/Refined-cora-citeseer/corax_adj.pkl\", 'rb') as f:\n",
    "    raw_adj = pickle.load(f)\n",
    "with open(\"./data/Refined-cora-citeseer/corax_features.pkl\", 'rb') as f:\n",
    "    raw_features = pickle.load(f)\n",
    "with open(\"./data/Refined-cora-citeseer/corax_labels.pkl\", 'rb') as f:\n",
    "    raw_labels = pickle.load(f)\n",
    "    raw_labels = np.argmax(raw_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44f109d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = raw_features.shape[0]\n",
    "num_edges = raw_adj.getnnz() // 2\n",
    "num_features = raw_features.shape[1]\n",
    "num_classes = raw_labels.max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aad08695",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "train_mask[range(1180)] = True\n",
    "val_mask[range(1180, 2180)] = True\n",
    "test_mask[range(2180, 2680)] = True\n",
    "num_train = int(torch.sum(train_mask))\n",
    "num_val = int(torch.sum(val_mask))\n",
    "num_test = int(torch.sum(test_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fe2902e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 2680.\n",
      "Number of edges: 5148.\n",
      "Number of features: 302.\n",
      "Number of classes: 7.\n",
      "Number of train samples: 1180.\n",
      "Number of val samples: 1000.\n",
      "Number of test samples: 500.\n",
      "Feature range: [-2.2968, 2.4000]\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of nodes: {}.\".format(num_nodes))\n",
    "print(\"Number of edges: {}.\".format(num_edges))\n",
    "print(\"Number of features: {}.\".format(num_features))\n",
    "print(\"Number of classes: {}.\".format(num_classes))\n",
    "print(\"Number of train samples: {}.\".format(num_train))\n",
    "print(\"Number of val samples: {}.\".format(num_val))\n",
    "print(\"Number of test samples: {}.\".format(num_test))\n",
    "print(\"Feature range: [{:.4f}, {:.4f}]\".format(raw_features.min(), raw_features.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b60c73c",
   "metadata": {},
   "source": [
    "### 1.2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7444c711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_acc(pred, labels, mask=None):\n",
    "    if mask is None:\n",
    "        return (torch.argmax(pred, dim=1) == labels).float().sum() / len(pred)\n",
    "    else:\n",
    "        return (torch.argmax(pred[mask], dim=1) == labels[mask]).float().sum() / int(torch.sum(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bb3d464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, features, adj, mask=None):\n",
    "    model.eval()\n",
    "    pred = model(features, adj, dropout=0)\n",
    "    pred_label = torch.argmax(pred, dim=1)\n",
    "    acc = eval_acc(pred[:len(mask)], labels, mask=mask)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd8472bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_to_tensor(adj):\n",
    "    sparse_row = torch.LongTensor(adj.row).unsqueeze(1)\n",
    "    sparse_col = torch.LongTensor(adj.col).unsqueeze(1)\n",
    "    sparse_concat = torch.cat((sparse_row, sparse_col), 1)\n",
    "    sparse_data = torch.FloatTensor(adj.data)\n",
    "    adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))\n",
    "\n",
    "    return adj_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dba19d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_norm(adj, order=-0.5):\n",
    "    adj = sp.eye(adj.shape[0]) + adj\n",
    "    for i in range(len(adj.data)):\n",
    "        if adj.data[i] > 0 and adj.data[i] != 1:\n",
    "            adj.data[i] = 1\n",
    "    adj = sp.coo_matrix(adj)\n",
    "\n",
    "    rowsum = np.array(adj.sum(1))\n",
    "    d_inv_sqrt = np.power(rowsum, order).flatten()\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "    adj = d_mat_inv_sqrt @ adj @ d_mat_inv_sqrt\n",
    "\n",
    "    return adj.tocoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88441f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'  #'cuda:0'\n",
    "\n",
    "adj = raw_adj\n",
    "adj = adj_norm(adj)\n",
    "adj = adj_to_tensor(adj).to(device)\n",
    "\n",
    "features = torch.FloatTensor(raw_features)\n",
    "labels = torch.LongTensor(raw_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea754e82",
   "metadata": {},
   "source": [
    "## 2. Model preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a75eda",
   "metadata": {},
   "source": [
    "### 2.1. Example of GCN ([Graph Convolutional Network](https://arxiv.org/abs/1609.02907))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "462bc27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNConv(nn.Module):\n",
    "    def __init__(self, in_features, out_features, activation=None, dropout=False):\n",
    "        super(GCNConv, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        self.activation = activation\n",
    "        self.dropout = dropout\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        if self.activation == F.leaky_relu:\n",
    "            gain = nn.init.calculate_gain('leaky_relu')\n",
    "        else:\n",
    "            gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_normal_(self.linear.weight, gain=gain)\n",
    "\n",
    "    def forward(self, x, adj, dropout=0):\n",
    "        x = self.linear(x)\n",
    "        x = torch.spmm(adj, x)\n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "        if self.dropout:\n",
    "            x = F.dropout(x, dropout)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_features, out_features, hidden_features, activation=F.relu, dropout=True):\n",
    "        super(GCN, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        if type(hidden_features) is int:\n",
    "            hidden_features = [hidden_features]\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(GCNConv(in_features, hidden_features[0], activation=activation, dropout=dropout))\n",
    "        for i in range(len(hidden_features) - 1):\n",
    "            self.layers.append(\n",
    "                GCNConv(hidden_features[i], hidden_features[i + 1], activation=activation, dropout=dropout))\n",
    "        self.layers.append(GCNConv(hidden_features[-1], out_features))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for layer in self.layers:\n",
    "            layer.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj, dropout=0):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, adj, dropout=dropout)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa83b67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (layers): ModuleList(\n",
      "    (0): GCNConv(\n",
      "      (linear): Linear(in_features=302, out_features=16, bias=True)\n",
      "    )\n",
      "    (1): GCNConv(\n",
      "      (linear): Linear(in_features=16, out_features=16, bias=True)\n",
      "    )\n",
      "    (2): GCNConv(\n",
      "      (linear): Linear(in_features=16, out_features=7, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = GCN(in_features=num_features, \n",
    "            out_features=num_classes, \n",
    "            hidden_features=[16, 16], \n",
    "            activation=F.relu)\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9ad7b0",
   "metadata": {},
   "source": [
    "### 2.2. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "220d43f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 200\n",
    "eval_every = 10\n",
    "dropout = 0.5\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a57fc9b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Train Loss 2.0604 | Train Acc 0.1195 | Val Loss 2.0613 | Val Acc 0.1340\n",
      "Epoch 00010 | Train Loss 1.4966 | Train Acc 0.4907 | Val Loss 1.5530 | Val Acc 0.4660\n",
      "Epoch 00020 | Train Loss 1.1267 | Train Acc 0.6144 | Val Loss 1.1453 | Val Acc 0.6090\n",
      "Epoch 00030 | Train Loss 0.8761 | Train Acc 0.7381 | Val Loss 0.9028 | Val Acc 0.7050\n",
      "Epoch 00040 | Train Loss 0.7892 | Train Acc 0.7500 | Val Loss 0.8046 | Val Acc 0.7270\n",
      "Epoch 00050 | Train Loss 0.7288 | Train Acc 0.7602 | Val Loss 0.7490 | Val Acc 0.7590\n",
      "Epoch 00060 | Train Loss 0.6538 | Train Acc 0.7712 | Val Loss 0.6848 | Val Acc 0.7670\n",
      "Epoch 00070 | Train Loss 0.6248 | Train Acc 0.8017 | Val Loss 0.6797 | Val Acc 0.7790\n",
      "Epoch 00080 | Train Loss 0.5734 | Train Acc 0.8093 | Val Loss 0.6743 | Val Acc 0.7860\n",
      "Epoch 00090 | Train Loss 0.5276 | Train Acc 0.8364 | Val Loss 0.6462 | Val Acc 0.7940\n",
      "Epoch 00100 | Train Loss 0.4916 | Train Acc 0.8475 | Val Loss 0.5938 | Val Acc 0.8110\n",
      "Epoch 00110 | Train Loss 0.4839 | Train Acc 0.8415 | Val Loss 0.6729 | Val Acc 0.7840\n",
      "Epoch 00120 | Train Loss 0.4544 | Train Acc 0.8585 | Val Loss 0.5585 | Val Acc 0.8260\n",
      "Epoch 00130 | Train Loss 0.4477 | Train Acc 0.8424 | Val Loss 0.5767 | Val Acc 0.8170\n",
      "Epoch 00140 | Train Loss 0.4207 | Train Acc 0.8678 | Val Loss 0.6016 | Val Acc 0.8230\n",
      "Epoch 00150 | Train Loss 0.4383 | Train Acc 0.8475 | Val Loss 0.5694 | Val Acc 0.8280\n",
      "Epoch 00160 | Train Loss 0.3931 | Train Acc 0.8771 | Val Loss 0.6152 | Val Acc 0.8280\n",
      "Epoch 00170 | Train Loss 0.4204 | Train Acc 0.8542 | Val Loss 0.6087 | Val Acc 0.8070\n",
      "Epoch 00180 | Train Loss 0.3973 | Train Acc 0.8568 | Val Loss 0.6474 | Val Acc 0.8230\n",
      "Epoch 00190 | Train Loss 0.3836 | Train Acc 0.8788 | Val Loss 0.5427 | Val Acc 0.8340\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    logits = model(features, adj, dropout)\n",
    "    logp = F.log_softmax(logits, 1)\n",
    "    train_loss = F.nll_loss(logp[train_mask], labels[train_mask])\n",
    "    val_loss = F.nll_loss(logp[val_mask], labels[val_mask])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % eval_every == 0:\n",
    "        train_acc = eval_acc(logp, labels, train_mask)\n",
    "        val_acc = eval_acc(logp, labels, val_mask)\n",
    "        print('Epoch {:05d} | Train Loss {:.4f} | Train Acc {:.4f} | Val Loss {:.4f} | Val Acc {:.4f}'.format(\n",
    "                    epoch, train_loss, train_acc, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2ef423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./saved_models/model_gcn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b1a759",
   "metadata": {},
   "source": [
    "### 2.3. Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "50cce2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8660\n"
     ]
    }
   ],
   "source": [
    "acc = eval_model(model, features, adj, test_mask)\n",
    "print(\"Test accuracy: {:.4f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8977c9",
   "metadata": {},
   "source": [
    "## 3. Example of graph injection attack (based on [FGSM](https://arxiv.org/abs/1412.6572))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66871c7f",
   "metadata": {},
   "source": [
    "### 3.1. Generate connections of injected nodes (randomly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5290f689",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inject = 10\n",
    "num_edge_max = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "847cc590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def injection(adj, n_inject, n_node, n_edge_max, test_index):\n",
    "    n_test = test_index.shape[0]\n",
    "    new_edges_x = []\n",
    "    new_edges_y = []\n",
    "    new_data = []\n",
    "    for i in range(n_inject):\n",
    "        islinked = np.zeros(n_test)\n",
    "        for j in range(n_edge_max):\n",
    "            x = i + n_node\n",
    "\n",
    "            yy = random.randint(0, n_test - 1)\n",
    "            while islinked[yy] > 0:\n",
    "                yy = random.randint(0, n_test - 1)\n",
    "\n",
    "            y = test_index[yy]\n",
    "            new_edges_x.extend([x, y])\n",
    "            new_edges_y.extend([y, x])\n",
    "            new_data.extend([1, 1])\n",
    "\n",
    "    add1 = sp.csr_matrix((n_inject, n_node))\n",
    "    add2 = sp.csr_matrix((n_node + n_inject, n_inject))\n",
    "    adj_attack = sp.vstack([adj, add1])\n",
    "    adj_attack = sp.hstack([adj_attack, add2])\n",
    "    adj_attack.row = np.hstack([adj_attack.row, new_edges_x])\n",
    "    adj_attack.col = np.hstack([adj_attack.col, new_edges_y])\n",
    "    adj_attack.data = np.hstack([adj_attack.data, new_data])\n",
    "    \n",
    "    return adj_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72019477",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_attack = injection(adj=raw_adj,\n",
    "                       n_inject=num_inject,\n",
    "                       n_node=num_nodes,\n",
    "                       n_edge_max=num_edge_max,\n",
    "                       test_index=torch.where(test_mask == True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2dbe2c29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[   0,    0,    0,  ..., 2689, 2689, 2689],\n",
       "                       [   0,  632, 1848,  ..., 2652, 2676, 2689]]),\n",
       "       values=tensor([0.2500, 0.2500, 0.2236,  ..., 0.0632, 0.0707, 0.0200]),\n",
       "       size=(2690, 2690), nnz=13938, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_attack = adj_norm(adj_attack)\n",
    "adj_attack = adj_to_tensor(adj_attack)\n",
    "adj_attack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c422596f",
   "metadata": {},
   "source": [
    "### 3.2. Update features by FGSM (Fast Gradient Sign Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15db4ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm(features, features_attack, adj_attack, labels, test_mask, n_epoch, epsilon, feat_min, feat_max, device='cpu'):\n",
    "    n_total = features.shape[0]\n",
    "    for i in range(n_epoch):\n",
    "        features_attack.requires_grad_(True)\n",
    "        features_attack.retain_grad()\n",
    "        \n",
    "        features_concat = torch.cat((features, features_attack), dim=0)\n",
    "        pred = model(features_concat, adj_attack) \n",
    "        pred_loss = -F.nll_loss(pred[:n_total][test_mask], labels[test_mask]).to(device)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        pred_loss.backward()\n",
    "        grad = features_attack.grad.data\n",
    "        features_attack = features_attack.clone() + epsilon * grad.sign()\n",
    "\n",
    "        features_attack = torch.clamp(features_attack, feat_min, feat_max)\n",
    "        features_attack = features_attack.detach()\n",
    "            \n",
    "        print(\"Epoch {}, Loss: {:.5f}, Test acc: {:.5f}\".format(i, pred_loss,\n",
    "                                                                eval_acc(pred[:n_total][test_mask],\n",
    "                                                                         labels[test_mask])))\n",
    "        \n",
    "    return features_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34349375",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 5.20593, Test acc: 0.85600\n",
      "Epoch 1, Loss: 5.62591, Test acc: 0.80600\n",
      "Epoch 2, Loss: 6.02167, Test acc: 0.75000\n",
      "Epoch 3, Loss: 6.41083, Test acc: 0.71400\n",
      "Epoch 4, Loss: 6.80009, Test acc: 0.68800\n",
      "Epoch 5, Loss: 7.18971, Test acc: 0.67600\n",
      "Epoch 6, Loss: 7.58298, Test acc: 0.65400\n",
      "Epoch 7, Loss: 7.97815, Test acc: 0.64400\n",
      "Epoch 8, Loss: 8.37593, Test acc: 0.63600\n",
      "Epoch 9, Loss: 8.77523, Test acc: 0.63200\n",
      "Epoch 10, Loss: 9.17685, Test acc: 0.61800\n",
      "Epoch 11, Loss: 9.58056, Test acc: 0.61400\n",
      "Epoch 12, Loss: 9.98615, Test acc: 0.60400\n",
      "Epoch 13, Loss: 10.39431, Test acc: 0.59200\n",
      "Epoch 14, Loss: 10.80378, Test acc: 0.58200\n",
      "Epoch 15, Loss: 11.21489, Test acc: 0.57600\n",
      "Epoch 16, Loss: 11.62671, Test acc: 0.57400\n",
      "Epoch 17, Loss: 12.03965, Test acc: 0.56600\n",
      "Epoch 18, Loss: 12.45364, Test acc: 0.56400\n",
      "Epoch 19, Loss: 12.86957, Test acc: 0.55600\n",
      "Epoch 20, Loss: 13.28626, Test acc: 0.55600\n",
      "Epoch 21, Loss: 13.30542, Test acc: 0.55600\n",
      "Epoch 22, Loss: 13.32370, Test acc: 0.55600\n",
      "Epoch 23, Loss: 13.33352, Test acc: 0.55600\n",
      "Epoch 24, Loss: 13.34335, Test acc: 0.55800\n",
      "Epoch 25, Loss: 13.34968, Test acc: 0.55600\n",
      "Epoch 26, Loss: 13.35644, Test acc: 0.55600\n",
      "Epoch 27, Loss: 13.36021, Test acc: 0.55600\n",
      "Epoch 28, Loss: 13.36411, Test acc: 0.55400\n",
      "Epoch 29, Loss: 13.36713, Test acc: 0.55400\n",
      "Epoch 30, Loss: 13.36962, Test acc: 0.55200\n",
      "Epoch 31, Loss: 13.37186, Test acc: 0.55000\n",
      "Epoch 32, Loss: 13.37368, Test acc: 0.55200\n",
      "Epoch 33, Loss: 13.37528, Test acc: 0.55200\n",
      "Epoch 34, Loss: 13.37610, Test acc: 0.55200\n",
      "Epoch 35, Loss: 13.37768, Test acc: 0.55200\n",
      "Epoch 36, Loss: 13.37828, Test acc: 0.55000\n",
      "Epoch 37, Loss: 13.37947, Test acc: 0.55000\n",
      "Epoch 38, Loss: 13.37986, Test acc: 0.55000\n",
      "Epoch 39, Loss: 13.38096, Test acc: 0.55000\n",
      "Epoch 40, Loss: 13.38122, Test acc: 0.54800\n",
      "Epoch 41, Loss: 13.38210, Test acc: 0.54800\n",
      "Epoch 42, Loss: 13.38213, Test acc: 0.54800\n",
      "Epoch 43, Loss: 13.38312, Test acc: 0.54800\n",
      "Epoch 44, Loss: 13.38301, Test acc: 0.54800\n",
      "Epoch 45, Loss: 13.38407, Test acc: 0.54800\n",
      "Epoch 46, Loss: 13.38382, Test acc: 0.54800\n",
      "Epoch 47, Loss: 13.38471, Test acc: 0.54800\n",
      "Epoch 48, Loss: 13.38437, Test acc: 0.54800\n",
      "Epoch 49, Loss: 13.38534, Test acc: 0.54800\n"
     ]
    }
   ],
   "source": [
    "features_attack = torch.zeros([num_inject, num_features], dtype=torch.float).to(device)\n",
    "features_attack.requires_grad_(True)\n",
    "features_attack = fgsm(features=features, \n",
    "                       features_attack=features_attack,\n",
    "                       adj_attack=adj_attack,\n",
    "                       labels=labels,\n",
    "                       test_mask=test_mask,\n",
    "                       n_epoch=50,\n",
    "                       epsilon=0.1,\n",
    "                       feat_min=-2.0,\n",
    "                       feat_max=2.0,\n",
    "                       device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c0a942e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "np.save(\"./results/features_attack.npy\", features_attack.detach().numpy())\n",
    "with open(\"./results/adj_attack.pkl\", 'wb') as f:\n",
    "    pickle.dump(adj_attack, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee074c7d",
   "metadata": {},
   "source": [
    "## 4. Evaluation on other GNN models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d828d06",
   "metadata": {},
   "source": [
    "### 4.1. Example of GIN ([Graph Isomorphism Network](https://arxiv.org/abs/1810.00826))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "49f6aac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GINConv(nn.Module):\n",
    "    def __init__(self, in_features, out_features, activation=F.relu, eps=0, batchnorm=False, dropout=False):\n",
    "        super(GINConv, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_features, out_features)\n",
    "        self.linear2 = nn.Linear(out_features, out_features)\n",
    "        self.activation = activation\n",
    "        self.eps = torch.nn.Parameter(torch.Tensor([eps]))\n",
    "        self.batchnorm = batchnorm\n",
    "        if batchnorm:\n",
    "            self.norm = nn.BatchNorm1d(out_features)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        if self.activation == F.leaky_relu:\n",
    "            gain = nn.init.calculate_gain('leaky_relu')\n",
    "        else:\n",
    "            gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_normal_(self.linear.weight, gain=gain)\n",
    "\n",
    "    def forward(self, x, adj, dropout=0):\n",
    "        y = torch.spmm(adj, x)\n",
    "        x = y + (1 + self.eps) * x\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        if self.batchnorm:\n",
    "            x = self.norm(x)\n",
    "        if self.dropout:\n",
    "            x = F.dropout(x, dropout)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class GIN(nn.Module):\n",
    "    def __init__(self, in_features, out_features, hidden_features, activation=F.relu, dropout=True):\n",
    "        super(GIN, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        if type(hidden_features) is int:\n",
    "            hidden_features = [hidden_features]\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        self.layers.append(GINConv(in_features, hidden_features[0], activation=activation, dropout=dropout))\n",
    "        for i in range(len(hidden_features) - 1):\n",
    "            self.layers.append(\n",
    "                GINConv(hidden_features[i], hidden_features[i + 1], activation=activation))\n",
    "        self.linear1 = nn.Linear(hidden_features[-2], hidden_features[-1])\n",
    "        self.linear2 = nn.Linear(hidden_features[-1], out_features)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for layer in self.layers:\n",
    "            layer.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj, dropout=0):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, adj, dropout=dropout)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.dropout(x, dropout)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dc1d8725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIN(\n",
      "  (layers): ModuleList(\n",
      "    (0): GINConv(\n",
      "      (linear1): Linear(in_features=302, out_features=16, bias=True)\n",
      "      (linear2): Linear(in_features=16, out_features=16, bias=True)\n",
      "    )\n",
      "    (1): GINConv(\n",
      "      (linear1): Linear(in_features=16, out_features=16, bias=True)\n",
      "      (linear2): Linear(in_features=16, out_features=16, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (linear1): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (linear2): Linear(in_features=16, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_gin = GIN(in_features=num_features, \n",
    "            out_features=num_classes, \n",
    "            hidden_features=[16, 16], \n",
    "            activation=F.relu)\n",
    "model_gin.load_state_dict(torch.load(\"./saved_models/model_gin.pt\"))\n",
    "model_gin.to(device)\n",
    "print(model_gin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ad5c75bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy (Original): 0.7980\n"
     ]
    }
   ],
   "source": [
    "acc = eval_model(model_gin, features, adj, test_mask)\n",
    "print(\"Test accuracy (Original): {:.4f}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8cb6745f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy (Attacked): 0.4960\n"
     ]
    }
   ],
   "source": [
    "acc = eval_model(model_gin, torch.cat([features, features_attack]), adj_attack, test_mask)\n",
    "print(\"Test accuracy (Attacked): {:.4f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e90cea",
   "metadata": {},
   "source": [
    "### 4.2. Example of TAGCN ([Topological Adaptive Graph Convolutional Network](https://arxiv.org/abs/1710.10370))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e5024d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TAGConv(nn.Module):\n",
    "    def __init__(self, in_features, out_features, k=2, activation=None, dropout=False, batchnorm=False):\n",
    "        super(TAGConv, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.linear = nn.Linear(in_features * (k + 1), out_features)\n",
    "        self.batchnorm = batchnorm\n",
    "        if batchnorm:\n",
    "            self.norm_func = nn.BatchNorm1d(out_features, affine=False)\n",
    "        self.activation = activation\n",
    "        self.dropout = dropout\n",
    "        self.k = k\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        if self.activation == F.leaky_relu:\n",
    "            gain = nn.init.calculate_gain('leaky_relu')\n",
    "        else:\n",
    "            gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_normal_(self.linear.weight, gain=gain)\n",
    "\n",
    "    def forward(self, x, adj, dropout=0):\n",
    "\n",
    "        fstack = [x]\n",
    "        for i in range(self.k):\n",
    "            y = torch.spmm(adj, fstack[-1])\n",
    "            fstack.append(y)\n",
    "        x = torch.cat(fstack, dim=-1)\n",
    "        x = self.linear(x)\n",
    "        if self.batchnorm:\n",
    "            x = self.norm_func(x)\n",
    "        if not (self.activation is None):\n",
    "            x = self.activation(x)\n",
    "        if self.dropout:\n",
    "            x = F.dropout(x, dropout)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class TAGCN(nn.Module):\n",
    "    def __init__(self, in_features, out_features, hidden_features, k, activation=F.leaky_relu, dropout=True):\n",
    "        super(TAGCN, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        if type(hidden_features) is int:\n",
    "            hidden_features = [hidden_features]\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(TAGConv(in_features, hidden_features[0], k, activation=activation, dropout=dropout))\n",
    "        for i in range(len(hidden_features) - 1):\n",
    "            self.layers.append(\n",
    "                TAGConv(hidden_features[i], hidden_features[i + 1], k, activation=activation, dropout=dropout))\n",
    "        self.layers.append(TAGConv(hidden_features[-1], out_features, k))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for layer in self.layers:\n",
    "            layer.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj, dropout=0):\n",
    "        for i in range(len(self.layers)):\n",
    "            x = self.layers[i](x, adj, dropout=dropout)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4be6a150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAGCN(\n",
      "  (layers): ModuleList(\n",
      "    (0): TAGConv(\n",
      "      (linear): Linear(in_features=906, out_features=64, bias=True)\n",
      "    )\n",
      "    (1): TAGConv(\n",
      "      (linear): Linear(in_features=192, out_features=64, bias=True)\n",
      "    )\n",
      "    (2): TAGConv(\n",
      "      (linear): Linear(in_features=192, out_features=7, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_tagcn = TAGCN(in_features=num_features, \n",
    "                    out_features=num_classes, \n",
    "                    hidden_features=[64, 64], \n",
    "                    k=2,\n",
    "                    activation=F.leaky_relu)\n",
    "model_tagcn.load_state_dict(torch.load(\"./saved_models/model_tagcn.pt\"))\n",
    "model_tagcn.to(device)\n",
    "print(model_tagcn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4f1a90dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy (Original): 0.8660\n"
     ]
    }
   ],
   "source": [
    "acc = eval_model(model_tagcn, features, adj, test_mask)\n",
    "print(\"Test accuracy (Original): {:.4f}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f6bbee77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy (Attacked): 0.5540\n"
     ]
    }
   ],
   "source": [
    "acc = eval_model(model_tagcn, torch.cat([features, features_attack]), adj_attack, test_mask)\n",
    "print(\"Test accuracy (Attacked): {:.4f}\".format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
